{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import plot_model\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.python.keras.layers import add, concatenate\n",
    "from tensorflow.python.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.layers import  Dropout,Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de8800",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fe82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"db-ratings.csv\", na_values=-1)\n",
    "dbmovies = pd.read_csv(\"db-movies.csv\")\n",
    "ml = pd.read_csv(\"ml-ratings.csv\", na_values=-1)\n",
    "links = pd.read_csv(\"links.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19a2f2",
   "metadata": {},
   "source": [
    "data precessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f27816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbmovies = dbmovies[[\"MOVIE_ID\",'NAME', \"IMDB_ID\"]]\n",
    "db = pd.merge(db,dbmovies, how = 'outer', on='MOVIE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop na, clean the data\n",
    "db = db.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['IMDB_ID_cleaned'] = db['IMDB_ID'].map(lambda x: x.strip('tt'))\n",
    "db['IMDB_ID_cleaned']= db['IMDB_ID_cleaned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.drop(['RATING_ID', 'MOVIE_ID','RATING_TIME','NAME','IMDB_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##rename the columns\n",
    "db.columns = ['userId', 'rating','imdbId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##statistics about the db data: rating counts, unique users, unique ids\n",
    "percent_missing = db.isnull().sum() * 100 / len(db)\n",
    "dbunique_users = db['userId'].unique()\n",
    "dbunique_imdbid = db['imdbId'].unique()\n",
    "print(percent_missing)\n",
    "print('missing values: ' + str(round(percent_missing['rating'], 2)) + '%')\n",
    "print('dbunique users: ' + str(len(dbunique_users)))\n",
    "print('dbunique imdbid: ' + str(len(dbunique_imdbid)))\n",
    "print(len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e84841",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Movielens, merge the tables, add imdbid with rating table, drop the unneccesary colmns\n",
    "ml = pd.merge(ml,links, how = 'outer', on='movieId')\n",
    "ml = ml.drop(['movieId','timestamp', 'tmdbId'], axis=1)\n",
    "ml = ml.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missingml = ml.isnull().sum() * 100 / len(ml)\n",
    "mlunique_users = ml['userId'].unique()\n",
    "mlunique_imdb = ml['imdbId'].unique()\n",
    "\n",
    "print('missing values: ' + str(round(percent_missingml['rating'], 2)) + '%')\n",
    "print('mlunique users: ' + str(len(mlunique_users)))\n",
    "print('mlunique imdb: ' + str(len(mlunique_imdb)))\n",
    "print(len(ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4474aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##slect the sub datasets ony have the same movies\n",
    "db = db.loc[db['imdbId'].isin(list(mlunique_imdb))]##only include the same movies\n",
    "\n",
    "dbunique_users = db['userId'].unique()\n",
    "dbunique_imdbid = db['imdbId'].unique()\n",
    "\n",
    "print('dbunique users: ' + str(len(dbunique_users)))\n",
    "print('dbunique imdbid: ' + str(len(dbunique_imdbid)))\n",
    "print(len(db))\n",
    "print(dbunique_imdbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking the douban dataset counting frequency\n",
    "def plot_frequency(db, k):\n",
    "    plt.style.use('ggplot')\n",
    "    fig, ax = plt.subplots(figsize=(8,5.5))\n",
    "    counts = db['imdbId'].value_counts(sort=True, ascending=False)\n",
    "    orig = counts.index.tolist()\n",
    "    counts2 = counts.reset_index(inplace=False, drop=True)\n",
    "    sub = counts2.index.tolist()\n",
    "\n",
    "    sns.lineplot(x=counts2.index[0:k], y=counts2[0:k]/counts2[0:k].sum(), ax=ax)\n",
    "    ax.fill_between(counts2.index[0:k], counts2[0:k]/counts2[0:k].sum(), alpha=0.5)\n",
    "    ax.set_ylabel(\"Relative frequency\")\n",
    "    ax.set_xlabel(\"top-k movies\")\n",
    "    plt.title('The relative frequency of top-k movies in Douban')\n",
    "\n",
    "plot_frequency(db, k=5000)\n",
    "#plt.savefig('The relative frequency of top-k items in Douban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "##slect the sub datasets ony have the same movies\n",
    "ml = ml.loc[ml['imdbId'].isin(list(dbunique_imdbid))]##only include the same movies\n",
    "mlunique_users = ml['userId'].unique()\n",
    "mlunique_imdb = ml['imdbId'].unique()\n",
    "\n",
    "print('mlunique users: ' + str(len(mlunique_users)))\n",
    "print('mlunique imdb: ' + str(len(mlunique_imdb)))\n",
    "print(len(ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc318e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency2(ml, k):\n",
    "    plt.style.use('ggplot')\n",
    "    fig, ax = plt.subplots(figsize=(8,5.5))\n",
    "    counts = ml['imdbId'].value_counts(sort=True, ascending=False)\n",
    "    orig = counts.index.tolist()\n",
    "    counts2 = counts.reset_index(inplace=False, drop=True)\n",
    "    sub = counts2.index.tolist()\n",
    "\n",
    "    sns.lineplot(x=counts2.index[0:k], y=counts2[0:k]/counts2[0:k].sum(), ax=ax)\n",
    "    ax.fill_between(counts2.index[0:k], counts2[0:k]/counts2[0:k].sum(), alpha=0.5)\n",
    "    ax.set_ylabel(\"relative frequency\")\n",
    "    ax.set_xlabel(\"top-k movies\")\n",
    "    plt.title('The relative frequency of top-k movies in IMDb')\n",
    "\n",
    "plot_frequency2(ml, k=5000)\n",
    "#plt.savefig('The relative frequency of top-k items in IMDb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##select subdatasets\n",
    "##select the top rated datasets\n",
    "def select(db, k, col):\n",
    "\n",
    "    top_values = db[col].value_counts().nlargest(k)\n",
    "    return db.loc[db[col].isin(top_values.index)]\n",
    "\n",
    "dbtop = select(db, k=1000, col='imdbId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtopuser = dbtop['userId'].unique()\n",
    "dbtopmovie = dbtop['imdbId'].unique()\n",
    "\n",
    "print(len(dbtopuser))\n",
    "print(len(dbtopmovie))\n",
    "print(len(dbtop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8525351",
   "metadata": {},
   "outputs": [],
   "source": [
    "##select the top rated 1000 moviesof db in movielens dataset\n",
    "mlsub = ml.loc[ml['imdbId'].isin(list(dbtopmovie))]##only include the same movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsubuser = mlsub['userId'].unique()\n",
    "mlsubmovie = mlsub['imdbId'].unique()\n",
    "\n",
    "print(len(mlsubuser))\n",
    "print(len(mlsubmovie))\n",
    "print(len(mlsub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check rating distribution\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(data = dbtop, x= 'rating', palette='Set2')\n",
    "plt.xlabel('Movie ratings of Douban')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##round up the rating to integer\n",
    "mlsub['rating'] = mlsub['rating'].apply(np.ceil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(data = mlsub, x= 'rating', palette='Set2')\n",
    "plt.xlabel('Movie ratings of ML')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##use dbtop and mlsub\n",
    "##transfer dbtop to arrays,creat a matrix where rows are users, columns are movies\n",
    "dbtop_arr = dbtop.pivot(index = \"userId\",columns = \"imdbId\",values = \"rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899dcc1c",
   "metadata": {},
   "source": [
    "Train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train/val/test split\n",
    "##Split the data into random 90%–10% train-test sets\n",
    "train_db, test_db = train_test_split(dbtop_arr, \n",
    "                                     test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data into matrix\n",
    "matrix_train_db = train_db.to_numpy(dtype = 'float')\n",
    "matrix_train_db[np.isnan(matrix_train_db)] = 0\n",
    "matrix_train_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc45576",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_test_db = test_db.to_numpy(dtype = 'float')\n",
    "matrix_test_db[np.isnan(matrix_test_db)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de06fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix_train_db.shape)\n",
    "print(matrix_test_db.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5450f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##mlsub data processing\n",
    "mlsub_arr = mlsub.pivot(index = \"userId\",columns = \"imdbId\",values = \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train/val/test split\n",
    "##Split the data into random 90%–10% train-test sets\n",
    "train_ml, test_ml = train_test_split(mlsub_arr,\n",
    "                                     test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train_ml = train_ml.to_numpy(dtype = 'float')\n",
    "matrix_train_ml[np.isnan(matrix_train_ml)] = 0\n",
    "matrix_train_ml\n",
    "matrix_test_ml = test_ml.to_numpy(dtype = 'float')\n",
    "matrix_test_ml[np.isnan(matrix_test_ml)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ea439",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix_train_ml.shape)\n",
    "print(matrix_test_ml.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c167b",
   "metadata": {},
   "source": [
    "Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0127f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plots error & rmse\n",
    "def show_error(history, skip):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(np.arange(skip, len(loss), 1), loss[skip:])\n",
    "    plt.plot(np.arange(skip, len(loss), 1), val_loss[skip:])\n",
    "    plt.title('model train vs validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rmse(history, skip):\n",
    "    rmse = history.history['masked_rmse_clip']\n",
    "    val_rmse = history.history['val_masked_rmse_clip']\n",
    "    plt.plot(np.arange(skip, len(rmse), 1), rmse[skip:])\n",
    "    plt.plot(np.arange(skip, len(val_rmse), 1), val_rmse[skip:])\n",
    "    plt.title('model train vs validation masked_rmse')\n",
    "    plt.ylabel('rmse')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##loss fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "  # masked function\n",
    "    mask_true = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "  # masked squared error\n",
    "    masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "    masked_mse = K.sum(masked_squared_error, axis=-1) / K.maximum(K.sum(mask_true, axis=-1), 1)\n",
    "    return masked_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f13929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_rmse(y_true, y_pred):\n",
    "  # masked function\n",
    "    mask_true = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "  # masked squared error\n",
    "    masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "    masked_rmse = K.sqrt(K.sum(masked_squared_error, axis=-1) / K.maximum(K.sum(mask_true, axis=-1), 1))\n",
    "    return masked_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1188c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_rmse_clip(y_true, y_pred):\n",
    "  # masked function\n",
    "    mask_true = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "    y_pred = K.clip(y_pred, 1, 5)\n",
    "  # masked squared error\n",
    "    masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "    masked_rmse = K.sqrt(K.sum(masked_squared_error, axis=-1) / K.maximum(K.sum(mask_true, axis=-1), 1))\n",
    "    return masked_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5a6c8",
   "metadata": {},
   "source": [
    "build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627746ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "####hyparparameter tuning, create the model, check architeture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deep_AE_model(X, layers, activation, last_activation, dropout, regularizer_encode, regularizer_decode, side_infor_size=0):\n",
    "    input_layer = x = Input(shape=(X.shape[1],), name='UserRating')\n",
    "    x = Dense(layers[0], activation=activation, kernel_regularizer=regularizers.l2(regularizer_encode))(x)\n",
    "    x = Dense(layers[1], activation=activation, kernel_regularizer=regularizers.l2(regularizer_encode))(x)\n",
    "    x = Dropout(rate = dropout)(x)\n",
    "    x = Dense(layers[2], activation=activation, kernel_regularizer=regularizers.l2(regularizer_decode))(x)\n",
    "    output_layer = Dense(X.shape[1]-side_infor_size, activation=last_activation, kernel_regularizer=regularizers.l2(regularizer_decode))(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers = [100, 50, 100]\n",
    "layers = [256, 512, 256]\n",
    "#layers = [500,100,500]\n",
    "dropout = 0.8\n",
    "#learning_rate = 0.001\n",
    "# activation = 'sigmoid'\n",
    "#last_activation = 'linear'\n",
    "activation = 'selu'\n",
    "last_activation = 'selu'\n",
    "regularizer_encode = 0.001\n",
    "regularizer_decode = 0.001\n",
    "adam = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deep_AE_model(matrix_train_db, layers, activation, last_activation, dropout, regularizer_encode, regularizer_decode)\n",
    "model.compile(optimizer = 'adam',loss=masked_mse, metrics=[masked_rmse_clip]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='masked_rmse_clip', patience= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fit the model\n",
    "hist_Deep_AE = model.fit(x=matrix_train_db, y=matrix_train_db,\n",
    "                  epochs=100,\n",
    "                  batch_size= 128, validation_split= 0.1 ,callbacks = [stop_early],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##confirm the architeture, use gridsearch to choose the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function, learning_rate):\n",
    "    input_layer = x = Input(shape=(X.shape[1],))\n",
    "    x = Dense(256, activation=activation_function, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = Dense(512, activation=activation_function, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = Dropout(rate = 0.8)(x)\n",
    "    x = Dense(256, activation=activation_function, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    output_layer = Dense(X.shape[1], activation='selu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    adam = optimizers.Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer = 'adam', loss=masked_mse, metrics=[masked_rmse_clip])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438843bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the scoring function\n",
    "def rmse(y_true, y_pred):\n",
    "    mask_true = np.not_equal(y_true, 0).astype(float)\n",
    "    y_pred = np.clip(y_pred, 1, 5)\n",
    "    square_error = np.square(mask_true * (y_true - y_pred))\n",
    "    rmse = np.sqrt(np.sum(square_error,axis=-1)/np.maximum(np.sum(mask_true,axis=-1),1))\n",
    "    return np.mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4814c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = make_scorer(rmse,greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b733a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##input data\n",
    "X = matrix_train_db\n",
    "Y = matrix_train_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [128,256,512]\n",
    "activation_function = ['selu','elu']\n",
    "learning_rate = [0.01,0.001,0.0001]\n",
    "param_grid = dict(batch_size = batch_size, activation_function=activation_function, learning_rate = learning_rate)\n",
    "\n",
    "# create model\n",
    "model1 = KerasRegressor(build_fn=create_model, epochs = 30, verbose=2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='masked_rmse_clip', patience=5)\n",
    "grid = GridSearchCV(estimator=model1, scoring= rmse, param_grid=param_grid, n_jobs = 2, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "##grid search graph\n",
    "\n",
    "sns.set()\n",
    "\n",
    "def plot_tuning_results(df_val):\n",
    "    \n",
    "    df_temp = df_val[:][df_val.batch_size != 256].sort_values(by=['learning_rate', 'activation_function'])\n",
    "    df_128 = df_temp[:][df_temp.batch_size != 512].sort_values(by=['learning_rate', 'activation_function'])\n",
    "    df_256 = df_val[:][df_val.batch_size == 256].sort_values(by=['learning_rate', 'activation_function'])\n",
    "    df_512 = df_val[:][df_val.batch_size == 512].sort_values(by=['learning_rate', 'activation_function'])\n",
    "\n",
    "    pivot1 = df_128.pivot_table(index='learning_rate',columns='activation_function',values='RMSE')\n",
    "    pivot2 = df_256.pivot_table(index='learning_rate',columns='activation_function',values='RMSE')\n",
    "    pivot3 = df_512.pivot_table(index='learning_rate',columns='activation_function',values='RMSE')\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n",
    "\n",
    "    sns.heatmap(pivot1,vmin=0.4,vmax=0.55,annot=True,linewidths=0.4,ax=ax1,cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "    sns.heatmap(pivot2,vmin=0.4,vmax=0.55,annot=True,linewidths=0.4,ax=ax2,cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "    sns.heatmap(pivot3,vmin=0.4,vmax=0.55,annot=True,linewidths=0.4,ax=ax3,cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "    \n",
    "    ax1.set_title(\"batch_size: 128\")\n",
    "    ax3.set_title(\"batch_size: 512\")\n",
    "    ax2.set_title(\"batch_size: 256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "df_grid\n",
    "df_grid['RMSE'] = np.round(np.abs(grid.cv_results_[\"mean_test_score\"]),3)\n",
    "plot_tuning_results(df_grid)\n",
    "#plt.savefig('output.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###bulid a new model with the best parameters and train on the whole dataset, benefit is you could train more epochs\n",
    "bestmodel_db = create_model(activation_function = 'selu', learning_rate=0.01)\n",
    "bestmodel_db.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='masked_rmse_clip', patience=5)\n",
    "hist_best = bestmodel_db.fit(x=matrix_train_db, y=matrix_train_db, batch_size=512,validation_split= 0.1,\n",
    "                  epochs=100,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca59348",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate the model \n",
    "test_db = bestmodel_db.evaluate(matrix_test_db, matrix_test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cross-test\n",
    "test_ml = bestmodel_db.evaluate(matrix_test_ml, matrix_test_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd250206",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the weights\n",
    "bestmodel_db.save_weights(\"db_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##retain the model on another dataset\n",
    "hist_db_retrain = bestmodel_db.fit(x=matrix_train_ml, y=matrix_train_ml, batch_size=512,\n",
    "                  epochs=100,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate the retrained model \n",
    "test_ml2 = bestmodel_db.evaluate(matrix_test_ml, matrix_test_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16915aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##additonal experiemnt\n",
    "##creat a new model with random parameters(activation = relu, lr = 0.01, batch_size = 128) but load the weights of best model, to check if the model performance well on the other dataset\n",
    "test_model_db = create_model(activation_function = 'relu',learning_rate=0.001)\n",
    "test_model_db.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the first model's weights\n",
    "test_model_db.load_weights(\"db_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27705dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fit the model\n",
    "hist_test2 = test_model_db.fit(x=matrix_train_ml, y=matrix_train_ml, batch_size=128,\n",
    "                  epochs=100,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate the test model\n",
    "test_db2 = test_model_db.evaluate(matrix_test_ml, matrix_test_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2253416",
   "metadata": {},
   "outputs": [],
   "source": [
    "##the same processure on another dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
